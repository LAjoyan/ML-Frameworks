{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2889f1d",
   "metadata": {},
   "source": [
    "## Lecture 4 - Scikit-learn API (Del 1)\n",
    "\n",
    "** Assignment: Classification and regression with a common API **\n",
    "\n",
    "Instructions:\n",
    "\n",
    "- Use scikit-learn estimators and the .fit / .predict pattern\n",
    "- Compare models on the same dataset\n",
    "- Add short comments explaining results\n",
    "\n",
    "### Task 1: Dataset and split\n",
    "\n",
    "Load a dataset and create a reproducible train/test split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4c2fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load a dataset (iris, breast_cancer, or diabetes)\n",
    "from sklearn.datasets import load_iris, load_diabetes\n",
    "\n",
    "# In production,\n",
    "# data = pd.load_csv('filename.csv')\n",
    "# but the data may need more preprocessing.\n",
    "# With ready-made datasets, preprocessing is rarely needed,\n",
    "# but EDA is still very important!\n",
    "\n",
    "# If you have good ETL / data engineers, the data can be usable from the start.\n",
    "data = load_iris(as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f380c452",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5aeb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f00a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = data.target\n",
    "target_names = data.target_names\n",
    "\n",
    "print(\"X:\", X)\n",
    "print(\"y:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87573541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create train/test split with a fixed random_state\n",
    "\n",
    "# Here we often use a function (train_test_split)\n",
    "# The function splits our data neatly into piles of train and test\n",
    "# We could do this manually\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357a939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One thing to keep in mind.\n",
    "print(\"X_train shape:\", X_train.shape, \"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5fbb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It’s good to double-check that you still have all classes \n",
    "# from the entire dataset after splitting the data. \n",
    "# You can be unlucky with the split.\n",
    "\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49a4619",
   "metadata": {},
   "source": [
    "### An EDA step: we examine the data using plotting/visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88bf8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice examples\n",
    "\n",
    "# list[:] - retrieves all data\n",
    "# that is: [:] in a slice means everything\n",
    "print(X[:])\n",
    "\n",
    "# But : can be modified, we can retrieve all data before\n",
    "# or after a certain point\n",
    "\n",
    "# [12:] retrieves all data from row 12 and downward\n",
    "X[12:]\n",
    "\n",
    "# [:12] retrieves all data up to row 12\n",
    "X[:12]\n",
    "\n",
    "# We can also slice in more than one dimension\n",
    "# We do this by using a comma\n",
    "# for example: [[1,2,3],[4,5,6]]\n",
    "\n",
    "# Let's try\n",
    "\n",
    "# Note: with a DataFrame, we use iloc for slicing instead\n",
    "# of just brackets [], but the principle is the same.\n",
    "X.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efef825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# With plt.plot() we can plot data\n",
    "# plot() takes data in list form, which can be passed \n",
    "# in different ways\n",
    "\n",
    "# With plt.plot(), we create a line plot\n",
    "# Line plots have many settings\n",
    "# You can explore them when you need to plot\n",
    "# The \"o\" is an example of a setting\n",
    "# It makes us plot points instead of lines\n",
    "# plt.plot(X, y, \"o\")\n",
    "\n",
    "# Our data is high-dimensional (4 dimensions),\n",
    "# so we choose to plot two dimensions\n",
    "plt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=y, cmap=\"tab10\", s=30)\n",
    "\n",
    "plt.title(\"Iris: Sepal length vs Sepal width\")\n",
    "plt.xlabel(data.feature_names[0])\n",
    "plt.ylabel(data.feature_names[1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ee83f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Seaborn pairplot example\n",
    "# Seaborn is a good complement to matplotlib.\n",
    "# A very common use case is pairplot.\n",
    "# Pairplot plots high-dimensional data, broken down into\n",
    "# pairs of two dimensions, AS WELL AS the distribution of\n",
    "# all variables (histograms).\n",
    "\n",
    "sns.pairplot(data=data.frame, hue=\"target\", vars=data.feature_names, palette=\"tab10\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9843a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=data.data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a6a81",
   "metadata": {},
   "source": [
    "### Task 2: Two models, same API\n",
    "\n",
    "Train two models and use the same fit/predict workflow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f4489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train LogisticRegression (classification) OR LinearRegression (regression)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# First, we create a completely empty model\n",
    "LogReg = LogisticRegression(max_iter=100)\n",
    "\n",
    "# Then we fit it to our data\n",
    "# We train it: it tries to find relationships\n",
    "# between our X (features) and y (target)\n",
    "LogReg.fit(X_train, y_train)\n",
    "\n",
    "# We evaluate our model using test data\n",
    "y_pred = LogReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3941d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train SVC (classification) OR Ridge (regression)\n",
    "\n",
    "# We create an additional classification model in order to compare different ones.\n",
    "# In machine learning in general, this is very common and almost necessary.\n",
    "# We usually train many models for the same purpose and then compare them.\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import  accuracy_score, classification_report,confusion_matrix, ConfusionMatrixDisplay\n",
    "svc = SVC()\n",
    "\n",
    "# We do the same steps as above (for Logistic Regression).\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_svc = svc.predict(X_test)\n",
    "\n",
    "print(\"Our accuravy is: \", accuracy_score(y_test, y_pred_svc))\n",
    "print(classification_report(y_test, y_pred_svc))\n",
    "\n",
    "confusion_matrix3=confusion_matrix(y_test,y_pred_svc)\n",
    "ConfusionMatrixDisplay(confusion_matrix3).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92353de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Two models, same API (classification)\n",
    "# Use two different classifiers on the same dataset\n",
    "\n",
    "# The below is a standard way of training several models \n",
    "# of the same kind at the same time\n",
    "log_reg = LogisticRegression(max_iter=10000)\n",
    "svm_mod = SVC()\n",
    "\n",
    "print(\"\\nClassification models on Iris\")\n",
    "for model in [log_reg, svm_mod]:\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    print(f\"--- {model.__class__.__name__} ---\")\n",
    "    # Macro-average treats each class equally (good for multiclass)\n",
    "    print(\"Our accuravy is: \", accuracy_score(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16785ed",
   "metadata": {},
   "source": [
    "### Task 2 - Regression Continuation\n",
    "Below we continue with task 2, but now we will use two different regression models and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80b1cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREP: Doing the same as above, but for another dataset\n",
    "\n",
    "# Regression dataset: Diabetes\n",
    "diabetes = load_diabetes(as_frame=True)\n",
    "X_reg = diabetes.data\n",
    "y_reg = diabetes.target\n",
    "\n",
    "X_reg_train, X_reg_test, y_reg_train, y_reg_test = train_test_split(\n",
    "    X_reg, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Diabetes: histogram of target values\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.hist(y_reg, bins=20, color=\"steelblue\", edgecolor=\"black\")\n",
    "plt.title(\"Diabetes: Target distribution\")\n",
    "plt.xlabel(\"Disease progression\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9889a21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8df940a",
   "metadata": {},
   "source": [
    "### Task 3: Metrics\n",
    "Compute evaluation metrics and add a short comparison.          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbf1850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: For classification: accuracy, precision, recall, f1\n",
    "# We evaluate our model by comparing predictions to actual values\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "print(\"Our accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "confusion_matrix2=confusion_matrix(y_test,y_pred)\n",
    "ConfusionMatrixDisplay(confusion_matrix2).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab43a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: For regression: MAE and R2\n",
    "\n",
    "# Se ovan, vi gör utvärderingen i regressions-träningsloopen\n",
    "# TODO: Print a short comparison and comment on which model you prefer\n",
    "print(\"Done! You practiced the unified scikit-learn API.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0b3d0f",
   "metadata": {},
   "source": [
    "## BONUS: Plotting decision boundaries (classification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15362ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we train Regression models on this data, we \n",
    "# will try to predict disease progression for our \n",
    "# diabetes patients\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    ")\n",
    "\n",
    "LinReg = LinearRegression()\n",
    "ridge = Ridge() # we could add alpha and a solver here\n",
    "\n",
    "y_reg_pred = []\n",
    "for model in [LinReg, ridge]:\n",
    "    model.fit(X_reg_train, y_reg_train)\n",
    "\n",
    "    # Att spara värden från träning för mer analys (som nedan)\n",
    "    # är väldigt användbart\n",
    "    y_reg_pred.append(model.predict(X_reg_test))\n",
    "    \n",
    "    y_pred = model.predict(X_reg_test)\n",
    "    print(f\"--- {model.__class__.__name__} ---\")\n",
    "    print(\"Mean absolute error:\", mean_absolute_error(y_reg_test, y_pred))\n",
    "    print(\"r2 score:\", r2_score(y_reg_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd32f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BONUS: Plot Ridge predictions vs actual (good regression diagnostic)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(y_reg_test, y_reg_pred[1], color=\"teal\", s=30, alpha=0.7)\n",
    "min_val = min(y_reg_test.min(), y_reg_pred[0].min())\n",
    "max_val = max(y_reg_test.max(), y_reg_pred[0].max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], \"k--\", linewidth=1)\n",
    "plt.title(\"Ridge: Predicted vs actual (test set)\")\n",
    "plt.xlabel(\"Actual target\")\n",
    "plt.ylabel(\"Predicted target\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Ramverk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
