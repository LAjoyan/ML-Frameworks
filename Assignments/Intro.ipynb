{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91314c76",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Lektion 1 - ML-ramverk och arkitektur\n",
    "Assignment: Frameworks, tensors, and execution models\n",
    "\n",
    "Instructions:\n",
    "\n",
    "1. Complete the tasks below with short, runnable code snippets\n",
    "2. Run each section and observe the output\n",
    "3. Comment your code to explain what each part does\n",
    "4. Keep everything in this file unless stated otherwise\n",
    "   \"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c323a1a",
   "metadata": {},
   "source": [
    "## Task 1: Vector and matrix basics (NumPy)\n",
    "\n",
    "### TODO: Create two vectors (length 3) and compute:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa86f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = [5, 6, 9]\n",
    "b = [7, 21, 2]\n",
    "vector1 = np.array([1, 2, 3])\n",
    "vector2 = np.array([5, 8, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e8dd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product is : 179\n",
      "The dot product using two numpy arrays 60\n",
      "The dot product using a python list + python list 179\n",
      "The dot product using a python list + numpy array 44\n"
     ]
    }
   ],
   "source": [
    "# - dot product\n",
    "print(\"Dot product is :\", np.dot(a, b))\n",
    "dot_prod = np.dot(vector1, vector2)\n",
    "print(\"The dot product using two numpy arrays\", dot_prod)\n",
    "print(\"The dot product using a python list + python list\", np.dot(a, b))\n",
    "print(\"The dot product using a python list + numpy array\", np.dot(a, vector1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8874dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2_normalization for vector 1 is: 3.7416573867739413\n",
      "L2_normalization for vector 2 is: 16.06237840420901\n"
     ]
    }
   ],
   "source": [
    "# - L2 norm\n",
    "l2_norm = np.linalg.norm(vector1)\n",
    "print(\"L2_normalization for vector 1 is:\", l2_norm)\n",
    "l2_norm_vector2 = np.linalg.norm(vector2)\n",
    "print(\"L2_normalization for vector 2 is:\", l2_norm_vector2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe84b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cosine similarity of vector1 and vector2 is : 0.9983374884595828\n",
      "The cosine similarity of vector1 and vector2 is : 0.9983374884595828\n"
     ]
    }
   ],
   "source": [
    "# - cosine similarity\n",
    "cos_sim_v1_v2 = np.dot(vector1, vector2) / (l2_norm * l2_norm_vector2)\n",
    "# same as above\n",
    "cos_sim_v1_v2_ALTERNATIVE = dot_prod / (\n",
    "    l2_norm * l2_norm_vector2\n",
    ")  # we have variable name as dot_prod  and it is 60\n",
    "print(\"The cosine similarity of vector1 and vector2 is :\", cos_sim_v1_v2)\n",
    "print(\"The cosine similarity of vector1 and vector2 is :\", cos_sim_v1_v2_ALTERNATIVE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5a7dc2",
   "metadata": {},
   "source": [
    "### TODO: Create a 2x3 matrix and multiply it by a length-3 vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa744d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of our matrix multiplication is: [31 29]\n"
     ]
    }
   ],
   "source": [
    "matris1 = [[2, 4, 7], [1, 5, 6]]\n",
    "\n",
    "matrix_multiplication = matris1 @ vector1\n",
    "print(\"Result of our matrix multiplication is:\", matrix_multiplication)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ee30ae",
   "metadata": {},
   "source": [
    "## Task 2: Eager vs graph execution\n",
    "\n",
    "### TODO: Write a small function f(x) = x^3 + 2x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacc7861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We test the funktion with 7, the answer is: 357\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x**3 + 2 * x\n",
    "\n",
    "\n",
    "print(\"We test the funktion with 7, the answer is:\", f(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f895bf",
   "metadata": {},
   "source": [
    "### TODO: Implement f(x) in ONE of:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a34576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(357.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor(7.0)\n",
    "y = f(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74752f98",
   "metadata": {},
   "source": [
    "- As a rule, PyTorch code is run in eager mode (one line at a time).\n",
    "- If you use torch.compile, then it runs in graph mode.\n",
    "- However, I believe this does not work on the MPS backend (Mac) and requires CUDA.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5f2d6c",
   "metadata": {},
   "source": [
    "### TODO: Print the output and note how execution differs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d808eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "# device for amd\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e3a578",
   "metadata": {},
   "source": [
    "### 1. Eager Execution (Standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18fd4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution time: 0.0004260540008544922 seconds\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "# Create a tensor with 10,000 random values drawn from a normal (Gaussian) distribution.\n",
    "# If a CUDA-enabled GPU is available, the tensor is placed on the GPU.\n",
    "# Otherwise, the tensor is created on the CPU.\n",
    "\n",
    "x = torch.randn(10000, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Record the current time before running the computation.\n",
    "# This marks the start of the timing measurement.\n",
    "start_time = time.time()\n",
    "\n",
    "# Execute the function f(x), which applies the mathematical operation\n",
    "# f(x) = x^3 + 2x element-wise to all 10,000 values in the tensor.\n",
    "# The result is assigned to '_' to indicate that we do not care about\n",
    "# the output values here, only that the computation is performed.\n",
    "_ = f(x)\n",
    "\n",
    "# Record the current time after the computation and subtract the start time.\n",
    "# The result is the total time taken to execute the function f(x) in eager mode.\n",
    "eager_time = time.time() - start_time\n",
    "\n",
    "# Print the measured execution time in seconds.\n",
    "# This shows how long it took to apply the function to all 10,000 elements.\n",
    "print(f\"Eager execution time: {eager_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aa8928",
   "metadata": {},
   "source": [
    "### 2. Graph Execution (Compiled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ba200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph execution time: N/A (torch.compile failed)\n",
      "Reason: Cannot find a working triton installation. Either the package is not installed or it is too old. More information on installing Triton can be found at: https://github.com/triton-lang/triton\n",
      "\n",
      "Set TORCHDYNAMO_VERBOSE=1 for the internal stack trace (please do this especially if you're reporting a bug to PyTorch). For even more developer context, set TORCH_LOGS=\"+dynamo\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    compiled_f = torch.compile(f)\n",
    "    start_time = time.time()\n",
    "    _ = compiled_f(x)\n",
    "    graph_time = time.time() - start_time\n",
    "    print(f\"Graph execution time: {graph_time} seconds\")\n",
    "except Exception as e:\n",
    "    print(\"Graph execution time: N/A (torch.compile failed)\")\n",
    "    print(\"Reason:\", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30063c3",
   "metadata": {},
   "source": [
    "## Task 3: Framework comparison in code\n",
    "### TODO: Using scikit-learn, load the iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce4e7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211b54b1",
   "metadata": {},
   "source": [
    "### TODO: Train a LogisticRegression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c23c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9733333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lilit\\Documents\\GitHub\\ML-Ramverk\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:406: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X,y)\n",
    "\n",
    "print(model.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe125f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! You now have a first hands-on view of ML frameworks.\n",
      "Keep these snippets for future comparison in later lessons.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Train a tiny MLP (MLPClassifier) on the same data\n",
    "# TODO: Compare accuracy and write 3-5 comments in code about:\n",
    "# - speed\n",
    "# - API ergonomics\n",
    "# - when you would pick each approach\n",
    "\n",
    "print(\"Done! You now have a first hands-on view of ML frameworks.\")\n",
    "print(\"Keep these snippets for future comparison in later lessons.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Ramverk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
